{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc811e21-c636-4e9f-91e1-62517586fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â COMBINE P-VALUES ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b2ab64-527e-40b7-9633-8af8ce98af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def fisher_method_log10(pvalues):\n",
    "    df = 2 * len(pvalues)\n",
    "    return -np.log10(1 - chi2.cdf(-2 * sum(map(np.log, pvalues)), df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66bac482-a3bc-4762-bb71-45b22e69b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of relate file:\n",
      "       pos rs_id  3571428.500000  357142.937500  257030.656250  184981.281250  \\\n",
      "0  2781642     .               1              1              1              1   \n",
      "1  2781865     .               1              1              1              1   \n",
      "2  2781927     .               1              1              1              1   \n",
      "3  2782572     .               1              1              1              1   \n",
      "4  2783658     .               1              1              1              1   \n",
      "\n",
      "   133128.375000  95810.585938  68953.507812  49624.847656  ...  257.030640  \\\n",
      "0              1             1             1           1.0  ...   -0.118409   \n",
      "1              1             1             1           1.0  ...   -0.929843   \n",
      "2              1             1             1           1.0  ...   -1.058240   \n",
      "3              1             1             1           1.0  ...   -0.186075   \n",
      "4              1             1             1           1.0  ...    1.000000   \n",
      "\n",
      "   184.981262  133.128357  95.810577  68.953499  49.624844  35.714287  \\\n",
      "0   -0.163878   -0.216210  -0.290473  -0.370193  -0.000012  -0.000019   \n",
      "1   -0.480394   -0.409679  -0.364098  -0.099042  -0.073554  -0.000001   \n",
      "2   -1.014230   -0.293524  -0.409285  -0.843033  -0.540662  -0.348473   \n",
      "3   -0.199893   -0.218741  -0.203945  -0.211564  -0.176239  -0.097633   \n",
      "4    1.000000    1.000000   1.000000   1.000000   1.000000  -0.676691   \n",
      "\n",
      "   0.000000  when_DAF_is_half  when_mutation_has_freq2  \n",
      "0         0         -0.521446                -0.082692  \n",
      "1         0         -0.502876                -0.489434  \n",
      "2         0         -1.117520                -1.083170  \n",
      "3         0         -0.167312                -0.145357  \n",
      "4         0         -1.584070                -0.610668  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "First 5 rows of kasper file:\n",
      "  stat_name  site         p  stat  nr_coal           t1  t2  tree_left  \\\n",
      "0   nr_runs     3  1.000000     3       81   307.649048   0  2781609.5   \n",
      "1   nr_runs     4  0.552704    19      122  1131.935791   0  2781609.5   \n",
      "2   nr_runs     5  0.973672    81      146  4033.751221   0  2781896.0   \n",
      "3   nr_runs    11  0.357742    67      150  8016.371094   0  2782569.5   \n",
      "4   nr_runs    18  1.000000     3       50   133.772415   0  2782997.5   \n",
      "\n",
      "   tree_right  clade_left  clade_right  nr_mut        pos  \n",
      "0   2781896.0   2781609.5    2781896.0       2  2781642.0  \n",
      "1   2781896.0   2781609.5    2781896.0       2  2781865.0  \n",
      "2   2781956.5   2781896.0    2781956.5       1  2781927.0  \n",
      "3   2782997.5   2782569.5    2782997.5       3  2782572.0  \n",
      "4   2784477.5   2782997.5    2784477.5       2  2783658.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "relate_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\"\n",
    "\n",
    "kasper_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\"\n",
    "\n",
    "print(\"First 5 rows of relate file:\")\n",
    "file1 = pd.read_csv(relate_LWK, sep=' ')\n",
    "print(file1.head())\n",
    "\n",
    "# Read and print first 5 rows of HDF5 file\n",
    "print(\"\\nFirst 5 rows of kasper file:\")\n",
    "file2 = pd.read_hdf(kasper_LWK)\n",
    "print(file2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb11f6c1-3dc2-4c49-adfb-279ea06d8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in relate DataFrame:\n",
      "Rows: 83674\n",
      "Columns: 35\n",
      "\n",
      "Number of rows and columns in kasper DataFrame:\n",
      "Rows: 83273\n",
      "Columns: 13\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns for each DataFrame\n",
    "relate_rows, relate_columns = file1.shape\n",
    "kasper_rows, kasper_columns = file2.shape\n",
    "\n",
    "# Print the number of rows and columns for each DataFrame\n",
    "print(\"Number of rows and columns in relate DataFrame:\")\n",
    "print(\"Rows:\", relate_rows)\n",
    "print(\"Columns:\", relate_columns)\n",
    "\n",
    "print(\"\\nNumber of rows and columns in kasper DataFrame:\")\n",
    "print(\"Rows:\", kasper_rows)\n",
    "print(\"Columns:\", kasper_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3437d245-b4ea-48bc-a3d1-a3fdb3ac17fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file1, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file2, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_pvalues_LWK.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m combined_file:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Skip the header lines in both files\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mnext\u001b[39m(file1) \u001b[38;5;66;03m# file1 = Relate\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# file2 = Kasper\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Write the header line in the new file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     combined_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos,combined_pvalue\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/arifdp/lib/python3.8/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Open the files for reading and the new file for writing\n",
    "with open(\"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\", \"r\") as file1, open(\"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\", \"r\") as file2, open(\"combined_pvalues_LWK.csv\", \"w\") as combined_file:\n",
    "    # Skip the header lines in both files\n",
    "    next(file1) # file1 = Relate\n",
    "    next(file2) # file2 = Kasper\n",
    "\n",
    "    # Write the header line in the new file\n",
    "    combined_file.write(\"pos,combined_pvalue\\n\")\n",
    "\n",
    "    # Iterate through the rows of both files simultaneously until the end of either file is reached\n",
    "    while True:\n",
    "        # Read a line from each file\n",
    "        line1 = file1.readline()\n",
    "        line2 = file2.readline()\n",
    "\n",
    "        # Check if either file has reached its end\n",
    "        if not line1 or not line2:\n",
    "            break\n",
    "\n",
    "        # Parse the genomic position and p-value from each line\n",
    "        pos1, p_value1 = map(float, line1.strip().split(\",\"))\n",
    "        pos2, p_value2 = map(float, line2.strip().split(\",\"))\n",
    "\n",
    "        # Check if the genomic positions match\n",
    "        if pos1 != pos2:\n",
    "            raise ValueError(\"Genomic positions do not match between files.\")\n",
    "\n",
    "        # Combine p-values using Fisher's method\n",
    "        combined_pvalue = fisher_method_log10([p_value1, p_value2])\n",
    "\n",
    "        # Write combined genomic position and p-value to the new file\n",
    "        combined_file.write(f\"{pos1},{combined_pvalue}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "298dadb7-ccc0-4b4e-8f79-ef6e6619f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pos rs_id  3571428.500000  357142.937500  257030.656250  184981.281250  \\\n",
      "0  2781642     .               1              1              1              1   \n",
      "1  2781865     .               1              1              1              1   \n",
      "2  2781927     .               1              1              1              1   \n",
      "3  2782572     .               1              1              1              1   \n",
      "4  2783658     .               1              1              1              1   \n",
      "\n",
      "   133128.375000  95810.585938  68953.507812  49624.847656  ...  257.030640  \\\n",
      "0              1             1             1           1.0  ...   -0.118409   \n",
      "1              1             1             1           1.0  ...   -0.929843   \n",
      "2              1             1             1           1.0  ...   -1.058240   \n",
      "3              1             1             1           1.0  ...   -0.186075   \n",
      "4              1             1             1           1.0  ...    1.000000   \n",
      "\n",
      "   184.981262  133.128357  95.810577  68.953499  49.624844  35.714287  \\\n",
      "0   -0.163878   -0.216210  -0.290473  -0.370193  -0.000012  -0.000019   \n",
      "1   -0.480394   -0.409679  -0.364098  -0.099042  -0.073554  -0.000001   \n",
      "2   -1.014230   -0.293524  -0.409285  -0.843033  -0.540662  -0.348473   \n",
      "3   -0.199893   -0.218741  -0.203945  -0.211564  -0.176239  -0.097633   \n",
      "4    1.000000    1.000000   1.000000   1.000000   1.000000  -0.676691   \n",
      "\n",
      "   0.000000  when_DAF_is_half  when_mutation_has_freq2  \n",
      "0         0         -0.521446                -0.082692  \n",
      "1         0         -0.502876                -0.489434  \n",
      "2         0         -1.117520                -1.083170  \n",
      "3         0         -0.167312                -0.145357  \n",
      "4         0         -1.584070                -0.610668  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "  stat_name  site         p  stat  nr_coal           t1  t2  tree_left  \\\n",
      "0   nr_runs     3  1.000000     3       81   307.649048   0  2781609.5   \n",
      "1   nr_runs     4  0.552704    19      122  1131.935791   0  2781609.5   \n",
      "2   nr_runs     5  0.973672    81      146  4033.751221   0  2781896.0   \n",
      "3   nr_runs    11  0.357742    67      150  8016.371094   0  2782569.5   \n",
      "4   nr_runs    18  1.000000     3       50   133.772415   0  2782997.5   \n",
      "\n",
      "   tree_right  clade_left  clade_right  nr_mut        pos  \n",
      "0   2781896.0   2781609.5    2781896.0       2  2781642.0  \n",
      "1   2781896.0   2781609.5    2781896.0       2  2781865.0  \n",
      "2   2781956.5   2781896.0    2781956.5       1  2781927.0  \n",
      "3   2782997.5   2782569.5    2782997.5       3  2782572.0  \n",
      "4   2784477.5   2782997.5    2784477.5       2  2783658.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fisher_method_log10(pvalues):\n",
    "    df = 2 * len(pvalues)\n",
    "    log_pvalues = np.log(np.maximum(pvalues, np.finfo(float).eps))  # Add a small constant to avoid zero or negative p-values\n",
    "    return -np.log10(1 - chi2.cdf(-2 * sum(log_pvalues), df))\n",
    "\n",
    "\n",
    "# File paths\n",
    "relate_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\"\n",
    "kasper_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\"\n",
    "\n",
    "# Read files into DataFrames\n",
    "file1 = pd.read_csv(relate_LWK, sep=' ')\n",
    "file2 = pd.read_hdf(kasper_LWK, dtype={'pos': int})  # Specify 'pos' column as integer\n",
    "\n",
    "print(file1.head())\n",
    "print(file2.head())\n",
    "\n",
    "# Open the combined file for writing\n",
    "with open(\"combined_pvalues_LWK.csv\", \"w\") as combined_file:\n",
    "    # Write the header line in the new file\n",
    "    combined_file.write(\"pos,combined_pvalue\\n\")\n",
    "\n",
    "    # Iterate through the rows of both DataFrames simultaneously\n",
    "  #  for index, row1 in file1.iterrows():\n",
    "   #     # Find corresponding row in file2 based on 'pos' column\n",
    "    #    row2 = file2[file2['pos'] == row1['pos']]\n",
    "#\n",
    " #       # Check if corresponding row exists in file2\n",
    "  #      if not row2.empty:\n",
    "   ##         # Combine p-values using Fisher's method\n",
    "     #       combined_pvalue = fisher_method_log10([row1['when_mutation_has_freq2'], row2['p']])\n",
    "\n",
    "            # Write combined genomic position and p-value to the new file\n",
    "      #      combined_file.write(f\"{row1['pos']},{combined_pvalue}\\n\")\n",
    "       # else:\n",
    "        #    print(f\"No corresponding row found in file2 for position {row1['pos']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f788515d-4757-4e67-a994-6e74a350baf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pos rs_id  3571428.500000  357142.937500  257030.656250  184981.281250  \\\n",
      "0  2781642     .               1              1              1              1   \n",
      "1  2781865     .               1              1              1              1   \n",
      "2  2781927     .               1              1              1              1   \n",
      "3  2782572     .               1              1              1              1   \n",
      "4  2783658     .               1              1              1              1   \n",
      "\n",
      "   133128.375000  95810.585938  68953.507812  49624.847656  ...  257.030640  \\\n",
      "0              1             1             1           1.0  ...   -0.118409   \n",
      "1              1             1             1           1.0  ...   -0.929843   \n",
      "2              1             1             1           1.0  ...   -1.058240   \n",
      "3              1             1             1           1.0  ...   -0.186075   \n",
      "4              1             1             1           1.0  ...    1.000000   \n",
      "\n",
      "   184.981262  133.128357  95.810577  68.953499  49.624844  35.714287  \\\n",
      "0   -0.163878   -0.216210  -0.290473  -0.370193  -0.000012  -0.000019   \n",
      "1   -0.480394   -0.409679  -0.364098  -0.099042  -0.073554  -0.000001   \n",
      "2   -1.014230   -0.293524  -0.409285  -0.843033  -0.540662  -0.348473   \n",
      "3   -0.199893   -0.218741  -0.203945  -0.211564  -0.176239  -0.097633   \n",
      "4    1.000000    1.000000   1.000000   1.000000   1.000000  -0.676691   \n",
      "\n",
      "   0.000000  when_DAF_is_half  when_mutation_has_freq2  \n",
      "0         0         -0.521446                -0.082692  \n",
      "1         0         -0.502876                -0.489434  \n",
      "2         0         -1.117520                -1.083170  \n",
      "3         0         -0.167312                -0.145357  \n",
      "4         0         -1.584070                -0.610668  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "  stat_name  site         p  stat  nr_coal           t1  t2  tree_left  \\\n",
      "0   nr_runs     3  1.000000     3       81   307.649048   0  2781609.5   \n",
      "1   nr_runs     4  0.552704    19      122  1131.935791   0  2781609.5   \n",
      "2   nr_runs     5  0.973672    81      146  4033.751221   0  2781896.0   \n",
      "3   nr_runs    11  0.357742    67      150  8016.371094   0  2782569.5   \n",
      "4   nr_runs    18  1.000000     3       50   133.772415   0  2782997.5   \n",
      "\n",
      "   tree_right  clade_left  clade_right  nr_mut      pos  \n",
      "0   2781896.0   2781609.5    2781896.0       2  2781642  \n",
      "1   2781896.0   2781609.5    2781896.0       2  2781865  \n",
      "2   2781956.5   2781896.0    2781956.5       1  2781927  \n",
      "3   2782997.5   2782569.5    2782997.5       3  2782572  \n",
      "4   2784477.5   2782997.5    2784477.5       2  2783658  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "relate_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\"\n",
    "kasper_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\"\n",
    "\n",
    "# Read files into DataFrames\n",
    "file1 = pd.read_csv(relate_LWK, sep=' ')\n",
    "file2 = pd.read_hdf(kasper_LWK)\n",
    "\n",
    "# Convert 'pos' column to integers in the second DataFrame\n",
    "file2['pos'] = file2['pos'].astype(int)\n",
    "\n",
    "print(file1.head())\n",
    "print(file2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474fdbee-f73c-4f20-aeda-aaa3a916abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pos rs_id  3571428.500000  357142.937500  257030.656250  184981.281250  \\\n",
      "0  2781642     .               1              1              1              1   \n",
      "1  2781865     .               1              1              1              1   \n",
      "2  2781927     .               1              1              1              1   \n",
      "3  2782572     .               1              1              1              1   \n",
      "4  2783658     .               1              1              1              1   \n",
      "\n",
      "   133128.375000  95810.585938  68953.507812  49624.847656  ...         p  \\\n",
      "0              1             1             1           1.0  ...  1.000000   \n",
      "1              1             1             1           1.0  ...  0.552704   \n",
      "2              1             1             1           1.0  ...  0.973672   \n",
      "3              1             1             1           1.0  ...  0.357742   \n",
      "4              1             1             1           1.0  ...  1.000000   \n",
      "\n",
      "   stat  nr_coal           t1  t2  tree_left  tree_right  clade_left  \\\n",
      "0     3       81   307.649048   0  2781609.5   2781896.0   2781609.5   \n",
      "1    19      122  1131.935791   0  2781609.5   2781896.0   2781609.5   \n",
      "2    81      146  4033.751221   0  2781896.0   2781956.5   2781896.0   \n",
      "3    67      150  8016.371094   0  2782569.5   2782997.5   2782569.5   \n",
      "4     3       50   133.772415   0  2782997.5   2784477.5   2782997.5   \n",
      "\n",
      "   clade_right  nr_mut  \n",
      "0    2781896.0       2  \n",
      "1    2781896.0       2  \n",
      "2    2781956.5       1  \n",
      "3    2782997.5       3  \n",
      "4    2784477.5       2  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "def fisher_method_log10(pvalues):\n",
    "    df = 2 * len(pvalues)\n",
    "    log_pvalues = np.log(np.maximum(pvalues, np.finfo(float).eps))  # Add a small constant to avoid zero or negative p-values\n",
    "    sum_log_pvalues = -2 * sum(log_pvalues)\n",
    "    return -np.log10(1 - chi2.cdf(sum_log_pvalues, df))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# File paths\n",
    "relate_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\"\n",
    "kasper_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\"\n",
    "\n",
    "# Read files into DataFrames\n",
    "file1 = pd.read_csv(relate_LWK, sep=' ')\n",
    "file2 = pd.read_hdf(kasper_LWK)\n",
    "\n",
    "# Convert 'pos' column to integers in the second DataFrame\n",
    "file2['pos'] = file2['pos'].astype(int)\n",
    "\n",
    "# Merge the two DataFrames on the 'pos' column\n",
    "merged_df = pd.merge(file1, file2, on='pos', how='inner')\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5018ad0-f802-482d-9fb1-7eae6df27f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pos  when_mutation_has_freq2         p\n",
      "0  2781642                -0.082692 -0.000000\n",
      "1  2781865                -0.489434  0.257507\n",
      "2  2781927                -1.083170  0.011587\n",
      "3  2782572                -0.145357  0.446430\n",
      "4  2783658                -0.610668 -0.000000\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "relate_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/steps/LWK/relate/run_relate/1000g_ppl_phased_haplotypes_selection.sele\"\n",
    "kasper_LWK = \"/home/ari/ari-intern/people/ari/ariadna-intern/results/1000g_ppl_phased_haplotypes_LWK_runstats.h5\"\n",
    "\n",
    "# Read files into DataFrames\n",
    "file1 = pd.read_csv(relate_LWK, sep=' ')\n",
    "file2 = pd.read_hdf(kasper_LWK)\n",
    "\n",
    "# Convert 'pos' column to integers in the second DataFrame\n",
    "file2['pos'] = file2['pos'].astype(int)\n",
    "\n",
    "# Merge the two DataFrames on the 'pos' column\n",
    "merged_df = pd.merge(file1[['pos', 'when_mutation_has_freq2']], file2[['pos', 'p']], on='pos', how='inner')\n",
    "\n",
    "# Apply -np.log10() function to the 'p' column\n",
    "merged_df['p'] = -np.log10(merged_df['p'])\n",
    "\n",
    "# Output the merged DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748b2cc-ca09-400c-837d-75ad74ca00a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
